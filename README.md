# Deep Learning 

This repository contains a collection of  notebooks demonstrating various applications of deep learning using Keras and PyTorch. The projects cover areas such as Natural Language Processing (NLP), Computer Vision (CV), and Time Series Modeling.

##  Notebook Contents

1. **`AE.ipynb`**  
   *Autoencoder* – Implementation of a basic autoencoder for dimensionality reduction or anomaly detection tasks.

2. **`AIR_PASSENGER RNNLSTM.ipynb`**  
   *Time Series Forecasting* – Predicting airline passenger numbers using RNN and LSTM models.

3. **`AirQuality (1)lstm.ipynb`**  
   *Air Quality Prediction* – Forecasting air pollutant levels using LSTM networks.

4. **`Attention.ipynb` & `Attention_mechanism (2).ipynb`**  
   *Attention Mechanism* – Applying attention in sequential models to enhance performance on NLP tasks.

5. **`cifarIn20Min CNN.ipynb`**  
   *Computer Vision* – Classifying CIFAR-10 images using a simple Convolutional Neural Network (CNN).

6. **`LSTM (1).ipynb` & `lstm_video.ipynb`**  
   *LSTM Exploration* – Experimentation with different LSTM architectures for sequential data analysis.

7. **`Mnist ANN.ipynb`**  
   *Handwritten Digit Recognition* – A basic Artificial Neural Network (ANN) applied to the MNIST dataset.

8. **`NLP.ipynb`**  
   *Natural Language Processing* – Introduction to NLP including tokenization, word embeddings, and text classification.

9. **`Séance 2 (CNN).ipynb`**  
   *Convolutional Neural Networks* – Hands-on implementation of a CNN model for image classification tasks, illustrating convolution, pooling, and regularization.

10. **`Transformers (2).ipynb`**  
    *Transformers* – A practical introduction to the Transformer architecture, covering multi-head attention, positional encoding, and stackable encoder-decoder blocks, as used in modern NLP models like BERT and GPT.

11. **`VAE.ipynb`**  
    *Variational AutoEncoder (VAE)* – Demonstrates how to build a VAE, a probabilistic generative model, used to create new samples similar to the training dataset (e.g., MNIST). Includes explanations of reconstruction loss and KL divergence.

---

##  Technologies Used

- Python  
- TensorFlow / Keras  
- PyTorch  
- NumPy, Pandas, Matplotlib, Seaborn  
