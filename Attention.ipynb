{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V87K7vWSrK0Y",
        "outputId": "8add3df9-1774-4b8f-c61b-5ccb907dfec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m2,560,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (\u001b[38;5;33mAttention\u001b[0m)                │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m,   │          \u001b[38;5;34m16,640\u001b[0m │\n",
              "│                                      │ \u001b[38;5;34m1\u001b[0m)]                         │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)                │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "│                                      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]                         │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,708,353\u001b[0m (10.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,708,353</span> (10.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,708,353\u001b[0m (10.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,708,353</span> (10.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 693ms/step - accuracy: 0.7144 - loss: 0.5248 - val_accuracy: 0.8676 - val_loss: 0.3079\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 728ms/step - accuracy: 0.9260 - loss: 0.2035 - val_accuracy: 0.8689 - val_loss: 0.3172\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 697ms/step - accuracy: 0.9647 - loss: 0.1057 - val_accuracy: 0.8587 - val_loss: 0.3637\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 698ms/step - accuracy: 0.9800 - loss: 0.0654 - val_accuracy: 0.8509 - val_loss: 0.4907\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 697ms/step - accuracy: 0.9891 - loss: 0.0359 - val_accuracy: 0.8416 - val_loss: 0.4851\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 123ms/step - accuracy: 0.8435 - loss: 0.4837\n",
            "Test Accuracy: 84.16%\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step\n",
            "to: 0.0005\n",
            "have: 0.0004\n",
            "after: 0.0002\n",
            "out: 0.0002\n",
            "atmosphere: 0.0004\n",
            "never: 0.0003\n",
            "more: 0.0006\n",
            "room: 0.0035\n",
            "and: 0.0010\n",
            "it: 0.0006\n",
            "so: 0.0007\n",
            "heart: 0.0031\n",
            "shows: 0.0023\n",
            "to: 0.0016\n",
            "years: 0.0015\n",
            "of: 0.0009\n",
            "every: 0.0019\n",
            "never: 0.0015\n",
            "going: 0.0016\n",
            "and: 0.0005\n",
            "help: 0.0002\n",
            "moments: 0.0002\n",
            "or: 0.0004\n",
            "of: 0.0004\n",
            "every: 0.0007\n",
            "chest: 0.0005\n",
            "visual: 0.0011\n",
            "movie: 0.0007\n",
            "except: 0.0007\n",
            "her: 0.0004\n",
            "was: 0.0002\n",
            "several: 0.0011\n",
            "of: 0.0006\n",
            "enough: 0.0002\n",
            "more: 0.0007\n",
            "with: 0.0008\n",
            "is: 0.0007\n",
            "now: 0.0042\n",
            "current: 0.0140\n",
            "film: 0.0108\n",
            "as: 0.0094\n",
            "you: 0.0152\n",
            "of: 0.0084\n",
            "mine: 0.0370\n",
            "potentially: 0.0067\n",
            "unfortunately: 0.0072\n",
            "of: 0.0059\n",
            "you: 0.0098\n",
            "than: 0.0018\n",
            "him: 0.0187\n",
            "that: 0.0063\n",
            "with: 0.0062\n",
            "out: 0.0018\n",
            "themselves: 0.0424\n",
            "her: 0.0160\n",
            "get: 0.0092\n",
            "for: 0.0032\n",
            "was: 0.0017\n",
            "camp: 0.0007\n",
            "of: 0.0007\n",
            "you: 0.0014\n",
            "movie: 0.0016\n",
            "sometimes: 0.0027\n",
            "movie: 0.0023\n",
            "that: 0.0016\n",
            "with: 0.0017\n",
            "scary: 0.0004\n",
            "but: 0.0005\n",
            "pratfalls: 0.0063\n",
            "to: 0.0055\n",
            "story: 0.0006\n",
            "wonderful: 0.0088\n",
            "that: 0.0033\n",
            "in: 0.0015\n",
            "seeing: 0.0114\n",
            "in: 0.0043\n",
            "character: 0.0039\n",
            "to: 0.0048\n",
            "of: 0.0034\n",
            "70s: 0.0006\n",
            "musicians: 0.0217\n",
            "with: 0.0124\n",
            "heart: 0.0566\n",
            "had: 0.0165\n",
            "shadows: 0.0847\n",
            "they: 0.0389\n",
            "of: 0.0209\n",
            "here: 0.0170\n",
            "that: 0.0138\n",
            "with: 0.0112\n",
            "her: 0.0092\n",
            "serious: 0.0038\n",
            "to: 0.0058\n",
            "have: 0.0069\n",
            "does: 0.0025\n",
            "when: 0.0008\n",
            "from: 0.0002\n",
            "why: 0.0003\n",
            "what: 0.0003\n",
            "have: 0.0004\n",
            "critics: 0.0024\n",
            "they: 0.0010\n",
            "is: 0.0010\n",
            "you: 0.0024\n",
            "that: 0.0021\n",
            "isn't: 0.0069\n",
            "one: 0.0010\n",
            "will: 0.0002\n",
            "very: 0.0007\n",
            "to: 0.0007\n",
            "as: 0.0011\n",
            "itself: 0.0266\n",
            "with: 0.0163\n",
            "other: 0.0224\n",
            "tricky: 0.0341\n",
            "in: 0.0161\n",
            "of: 0.0109\n",
            "seen: 0.0039\n",
            "over: 0.0005\n",
            "landed: 0.0122\n",
            "for: 0.0025\n",
            "anyone: 0.0014\n",
            "of: 0.0013\n",
            "and: 0.0004\n",
            "br: 0.0004\n",
            "show's: 0.0006\n",
            "to: 0.0006\n",
            "whether: 0.0005\n",
            "from: 0.0002\n",
            "than: 0.0001\n",
            "out: 0.0001\n",
            "themselves: 0.0050\n",
            "history: 0.0007\n",
            "he: 0.0006\n",
            "name: 0.0082\n",
            "half: 0.0019\n",
            "some: 0.0014\n",
            "br: 0.0008\n",
            "of: 0.0004\n",
            "'n: 0.0003\n",
            "odd: 0.0001\n",
            "was: 0.0001\n",
            "two: 0.0001\n",
            "most: 0.0001\n",
            "of: 0.0001\n",
            "mean: 0.0002\n",
            "for: 0.0001\n",
            "1: 0.0002\n",
            "any: 0.0001\n",
            "an: 0.0001\n",
            "boat: 0.0002\n",
            "she: 0.0003\n",
            "he: 0.0003\n",
            "should: 0.0005\n",
            "is: 0.0005\n",
            "thought: 0.0004\n",
            "frog: 0.0078\n",
            "but: 0.0013\n",
            "of: 0.0003\n",
            "script: 0.0004\n",
            "you: 0.0009\n",
            "not: 0.0002\n",
            "while: 0.0003\n",
            "history: 0.0001\n",
            "he: 0.0001\n",
            "heart: 0.0043\n",
            "to: 0.0032\n",
            "real: 0.0063\n",
            "at: 0.0016\n",
            "barrel: 0.0035\n",
            "but: 0.0024\n",
            "when: 0.0007\n",
            "from: 0.0002\n",
            "one: 0.0001\n",
            "bit: 0.0001\n",
            "then: 0.0001\n",
            "have: 0.0001\n",
            "two: 0.0001\n",
            "of: 0.0001\n",
            "script: 0.0001\n",
            "their: 0.0003\n",
            "with: 0.0004\n",
            "her: 0.0003\n",
            "nobody: 0.0039\n",
            "most: 0.0019\n",
            "that: 0.0018\n",
            "with: 0.0020\n",
            "wasn't: 0.0170\n",
            "to: 0.0101\n",
            "with: 0.0085\n",
            "armed: 0.0016\n",
            "acting: 0.0025\n",
            "watch: 0.0008\n",
            "an: 0.0020\n",
            "for: 0.0006\n",
            "with: 0.0006\n",
            "heartfelt: 0.0188\n",
            "film: 0.0106\n",
            "want: 0.0118\n",
            "an: 0.0165\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Embedding, LSTM, Dense, Input, Layer, Dropout, GlobalAveragePooling1D\n",
        ")\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Paramètres de configuration\n",
        "max_features = 20000  # Nombre de mots uniques dans le vocabulaire\n",
        "max_len = 200         # Longueur maximale des séquences\n",
        "embedding_dim = 128   # Dimension des vecteurs d'embedding\n",
        "\n",
        "# Charger et préparer le dataset IMDB\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Définir une couche d'attention personnalisée\n",
        "class Attention(Layer):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer=\"random_normal\",\n",
        "                                 trainable=True)\n",
        "        self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=\"zeros\",\n",
        "                                 trainable=True)\n",
        "        self.u = self.add_weight(shape=(input_shape[-1], 1),\n",
        "                                 initializer=\"random_normal\",\n",
        "                                 trainable=True)\n",
        "        super(Attention, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Calcul des scores d'attention\n",
        "        score = tf.nn.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
        "        attention_weights = tf.nn.softmax(tf.tensordot(score, self.u, axes=1), axis=1)\n",
        "        # Calcul du contexte pondéré\n",
        "        context_vector = tf.reduce_sum(inputs * attention_weights, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "# Construire le modèle avec LSTM et attention\n",
        "def build_model():\n",
        "    inputs = Input(shape=(max_len,))\n",
        "    x = Embedding(max_features, embedding_dim)(inputs)\n",
        "    x = LSTM(128, return_sequences=True)(x)  # Sortie de séquences pour l'attention\n",
        "    context_vector, attention_weights = Attention()(x)\n",
        "    x = Dropout(0.5)(context_vector)\n",
        "    outputs = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Initialiser et compiler le modèle\n",
        "model = build_model()\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "# Entraîner le modèle\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5, batch_size=64)\n",
        "\n",
        "# Évaluer le modèle\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Visualiser les poids d'attention pour une phrase\n",
        "def visualize_attention(input_sequence, word_index):\n",
        "    reverse_word_index = {v: k for k, v in word_index.items()}\n",
        "    words = [reverse_word_index.get(i, '?') for i in input_sequence]\n",
        "\n",
        "    input_sequence = pad_sequences([input_sequence], maxlen=max_len)\n",
        "    model_attention = Model(inputs=model.input, outputs=model.get_layer('attention').output)\n",
        "    context_vector, attention_weights = model_attention.predict(input_sequence)\n",
        "    attention_weights = attention_weights.squeeze()\n",
        "\n",
        "    # Afficher les mots et leurs poids\n",
        "    for word, weight in zip(words, attention_weights):\n",
        "        print(f\"{word}: {weight:.4f}\")\n",
        "\n",
        "# Exemple d'utilisation de la visualisation des poids d'attention\n",
        "sample_index = 0  # Index d'un échantillon dans le dataset\n",
        "visualize_attention(x_train[sample_index], imdb.get_word_index())\n"
      ]
    }
  ]
}