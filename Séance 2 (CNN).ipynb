{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2918bd45-de99-49bb-bfdc-f28759d942b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "#from keras.datasets import mnist\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Concatenate, Activation\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fba3c0a-3c00-4bc8-a476-77bdd7bc94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting absl-py (from keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (13.7.1)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Requirement already satisfied: h5py in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (3.11.0)\n",
      "Collecting optree (from keras)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Collecting ml-dtypes (from keras)\n",
      "  Downloading ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from optree->keras) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.0)\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading ml_dtypes-0.5.0-cp312-cp312-win_amd64.whl (213 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Installing collected packages: namex, optree, ml-dtypes, absl-py, keras\n",
      "Successfully installed absl-py-2.1.0 keras-3.6.0 ml-dtypes-0.5.0 namex-0.0.8 optree-0.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c72d99-dba0-4f1e-8150-92bcbe10f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/390.3 MB 10.1 MB/s eta 0:00:39\n",
      "   ---------------------------------------- 4.5/390.3 MB 11.2 MB/s eta 0:00:35\n",
      "    --------------------------------------- 6.8/390.3 MB 11.3 MB/s eta 0:00:34\n",
      "    --------------------------------------- 9.2/390.3 MB 11.4 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 11.8/390.3 MB 11.5 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 14.2/390.3 MB 11.5 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 16.5/390.3 MB 11.6 MB/s eta 0:00:33\n",
      "   - -------------------------------------- 19.1/390.3 MB 11.6 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 21.5/390.3 MB 11.7 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 24.1/390.3 MB 11.7 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 26.5/390.3 MB 11.7 MB/s eta 0:00:32\n",
      "   -- ------------------------------------- 29.1/390.3 MB 11.8 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 31.5/390.3 MB 11.7 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 34.1/390.3 MB 11.8 MB/s eta 0:00:31\n",
      "   --- ------------------------------------ 36.4/390.3 MB 11.8 MB/s eta 0:00:31\n",
      "   ---- ----------------------------------- 39.1/390.3 MB 11.8 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 41.7/390.3 MB 11.8 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 44.0/390.3 MB 11.8 MB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 46.4/390.3 MB 11.8 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 49.0/390.3 MB 11.8 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 51.6/390.3 MB 11.8 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 54.0/390.3 MB 11.8 MB/s eta 0:00:29\n",
      "   ----- ---------------------------------- 56.4/390.3 MB 11.8 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 59.0/390.3 MB 11.8 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 61.3/390.3 MB 11.8 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 64.0/390.3 MB 11.8 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 66.6/390.3 MB 11.9 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 69.2/390.3 MB 11.9 MB/s eta 0:00:28\n",
      "   ------- -------------------------------- 71.6/390.3 MB 11.8 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 74.2/390.3 MB 11.9 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 76.5/390.3 MB 11.9 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 79.2/390.3 MB 11.9 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 81.5/390.3 MB 11.8 MB/s eta 0:00:27\n",
      "   -------- ------------------------------- 83.9/390.3 MB 11.8 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 86.5/390.3 MB 11.8 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 88.9/390.3 MB 11.8 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 91.5/390.3 MB 11.8 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 93.8/390.3 MB 11.8 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 96.2/390.3 MB 11.9 MB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 98.8/390.3 MB 11.9 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 101.2/390.3 MB 11.9 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 103.8/390.3 MB 11.9 MB/s eta 0:00:25\n",
      "   ---------- ---------------------------- 106.2/390.3 MB 11.9 MB/s eta 0:00:24\n",
      "   ---------- ---------------------------- 108.8/390.3 MB 11.9 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 111.1/390.3 MB 11.8 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 113.8/390.3 MB 11.9 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 116.1/390.3 MB 11.9 MB/s eta 0:00:24\n",
      "   ----------- --------------------------- 118.8/390.3 MB 11.9 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 121.1/390.3 MB 11.8 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 123.7/390.3 MB 11.8 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 126.1/390.3 MB 11.8 MB/s eta 0:00:23\n",
      "   ------------ -------------------------- 128.7/390.3 MB 11.8 MB/s eta 0:00:23\n",
      "   ------------- ------------------------- 131.1/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 133.4/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 135.5/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   ------------- ------------------------- 137.9/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 140.2/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 142.6/390.3 MB 11.8 MB/s eta 0:00:22\n",
      "   -------------- ------------------------ 145.0/390.3 MB 11.8 MB/s eta 0:00:21\n",
      "   -------------- ------------------------ 147.6/390.3 MB 11.8 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 150.2/390.3 MB 11.8 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 152.6/390.3 MB 11.8 MB/s eta 0:00:21\n",
      "   --------------- ----------------------- 155.2/390.3 MB 11.8 MB/s eta 0:00:20\n",
      "   --------------- ----------------------- 157.8/390.3 MB 11.8 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 160.4/390.3 MB 11.8 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 162.8/390.3 MB 11.8 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 165.4/390.3 MB 11.8 MB/s eta 0:00:20\n",
      "   ---------------- ---------------------- 168.0/390.3 MB 11.8 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 170.7/390.3 MB 11.8 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 173.0/390.3 MB 11.8 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 175.6/390.3 MB 11.8 MB/s eta 0:00:19\n",
      "   ----------------- --------------------- 178.3/390.3 MB 11.8 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 180.6/390.3 MB 11.8 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 183.0/390.3 MB 11.8 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 185.6/390.3 MB 11.8 MB/s eta 0:00:18\n",
      "   ------------------ -------------------- 188.2/390.3 MB 11.8 MB/s eta 0:00:18\n",
      "   ------------------- ------------------- 190.8/390.3 MB 11.8 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 193.2/390.3 MB 11.8 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 195.8/390.3 MB 11.8 MB/s eta 0:00:17\n",
      "   ------------------- ------------------- 198.2/390.3 MB 11.8 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 200.8/390.3 MB 11.8 MB/s eta 0:00:17\n",
      "   -------------------- ------------------ 203.4/390.3 MB 11.8 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 205.8/390.3 MB 11.8 MB/s eta 0:00:16\n",
      "   -------------------- ------------------ 208.4/390.3 MB 11.8 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 211.0/390.3 MB 11.8 MB/s eta 0:00:16\n",
      "   --------------------- ----------------- 213.4/390.3 MB 11.8 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 216.0/390.3 MB 11.8 MB/s eta 0:00:15\n",
      "   --------------------- ----------------- 218.6/390.3 MB 11.8 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 221.0/390.3 MB 11.8 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 223.6/390.3 MB 11.8 MB/s eta 0:00:15\n",
      "   ---------------------- ---------------- 226.2/390.3 MB 11.8 MB/s eta 0:00:14\n",
      "   ---------------------- ---------------- 228.6/390.3 MB 11.8 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 231.2/390.3 MB 11.8 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 233.6/390.3 MB 11.8 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 236.2/390.3 MB 11.8 MB/s eta 0:00:14\n",
      "   ----------------------- --------------- 238.6/390.3 MB 11.8 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 241.2/390.3 MB 11.8 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 243.8/390.3 MB 11.8 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 246.4/390.3 MB 11.8 MB/s eta 0:00:13\n",
      "   ------------------------ -------------- 249.0/390.3 MB 11.8 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 251.7/390.3 MB 11.8 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 254.0/390.3 MB 11.8 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 256.6/390.3 MB 11.8 MB/s eta 0:00:12\n",
      "   ------------------------- ------------- 259.3/390.3 MB 11.9 MB/s eta 0:00:12\n",
      "   -------------------------- ------------ 261.6/390.3 MB 11.9 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 264.2/390.3 MB 11.9 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 266.6/390.3 MB 11.9 MB/s eta 0:00:11\n",
      "   -------------------------- ------------ 269.2/390.3 MB 11.9 MB/s eta 0:00:11\n",
      "   --------------------------- ----------- 271.6/390.3 MB 11.9 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 274.2/390.3 MB 11.9 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 276.8/390.3 MB 11.9 MB/s eta 0:00:10\n",
      "   --------------------------- ----------- 279.2/390.3 MB 11.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 281.8/390.3 MB 11.9 MB/s eta 0:00:10\n",
      "   ---------------------------- ---------- 284.4/390.3 MB 11.9 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 286.8/390.3 MB 11.9 MB/s eta 0:00:09\n",
      "   ---------------------------- ---------- 289.4/390.3 MB 11.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 291.8/390.3 MB 11.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 294.4/390.3 MB 11.9 MB/s eta 0:00:09\n",
      "   ----------------------------- --------- 297.0/390.3 MB 11.9 MB/s eta 0:00:08\n",
      "   ----------------------------- --------- 299.4/390.3 MB 11.9 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 302.0/390.3 MB 11.9 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 304.6/390.3 MB 11.9 MB/s eta 0:00:08\n",
      "   ------------------------------ -------- 307.2/390.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------------ -------- 309.6/390.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 312.2/390.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 314.8/390.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 317.2/390.3 MB 11.9 MB/s eta 0:00:07\n",
      "   ------------------------------- ------- 319.8/390.3 MB 11.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 322.2/390.3 MB 11.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 324.8/390.3 MB 11.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 327.4/390.3 MB 11.9 MB/s eta 0:00:06\n",
      "   -------------------------------- ------ 330.0/390.3 MB 11.9 MB/s eta 0:00:06\n",
      "   --------------------------------- ----- 332.4/390.3 MB 11.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 335.0/390.3 MB 11.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 337.4/390.3 MB 11.9 MB/s eta 0:00:05\n",
      "   --------------------------------- ----- 340.0/390.3 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 342.4/390.3 MB 11.9 MB/s eta 0:00:05\n",
      "   ---------------------------------- ---- 345.0/390.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 347.3/390.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 349.2/390.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 351.5/390.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 354.2/390.3 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------------------------------- --- 356.8/390.3 MB 11.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 359.1/390.3 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 361.8/390.3 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 364.4/390.3 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------------------------ -- 367.0/390.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 369.4/390.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 372.0/390.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 374.3/390.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 377.0/390.3 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 379.6/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.9/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.6/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.2/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  389.5/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 11.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 12.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 11.4 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.4/26.4 MB 12.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.0/26.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 10.0/26.4 MB 11.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.3/26.4 MB 12.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 14.9/26.4 MB 11.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.3/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.9/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 22.3/26.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 11.5 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 10.2 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorboard-data-server, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.0\n",
      "    Uninstalling ml_dtypes-0.5.0:\n",
      "      Successfully uninstalled ml_dtypes-0.5.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 libclang-18.1.1 ml-dtypes-0.4.1 opt-einsum-3.4.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "baff21c3-98b9-4bb7-a198-48f4f57c77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', sep = ',')\n",
    "test = pd.read_csv('test.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "6320486a-ff68-4574-9a30-ab3426848986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_3063</th>\n",
       "      <th>pixel_3064</th>\n",
       "      <th>pixel_3065</th>\n",
       "      <th>pixel_3066</th>\n",
       "      <th>pixel_3067</th>\n",
       "      <th>pixel_3068</th>\n",
       "      <th>pixel_3069</th>\n",
       "      <th>pixel_3070</th>\n",
       "      <th>pixel_3071</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>68</td>\n",
       "      <td>98</td>\n",
       "      <td>119</td>\n",
       "      <td>139</td>\n",
       "      <td>145</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>57</td>\n",
       "      <td>104</td>\n",
       "      <td>140</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>102</td>\n",
       "      <td>125</td>\n",
       "      <td>155</td>\n",
       "      <td>172</td>\n",
       "      <td>180</td>\n",
       "      <td>142</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>67</td>\n",
       "      <td>101</td>\n",
       "      <td>122</td>\n",
       "      <td>133</td>\n",
       "      <td>136</td>\n",
       "      <td>139</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>255</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>79</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>183</td>\n",
       "      <td>181</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>79</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0       59       43       50       68       98      119      139      145   \n",
       "1      154      126      105      102      125      155      172      180   \n",
       "2      255      253      253      253      253      253      253      253   \n",
       "3       28       37       38       42       44       40       40       24   \n",
       "4      170      168      177      183      181      177      181      184   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_3063  pixel_3064  pixel_3065  pixel_3066  \\\n",
       "0      149      149  ...          58          65          59          46   \n",
       "1      142      111  ...          42          67         101         122   \n",
       "2      253      253  ...          83          80          69          66   \n",
       "3       32       43  ...          39          59          42          44   \n",
       "4      189      189  ...          88          85          82          83   \n",
       "\n",
       "   pixel_3067  pixel_3068  pixel_3069  pixel_3070  pixel_3071  label  \n",
       "0          57         104         140          84          72      6  \n",
       "1         133         136         139         142         144      9  \n",
       "2          72          79          83          83          84      9  \n",
       "3          48          38          28          37          46      4  \n",
       "4          79          78          82          78          80      1  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7c1c3c9e-680e-43f7-bcc0-fdb401db7d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_3062</th>\n",
       "      <th>pixel_3063</th>\n",
       "      <th>pixel_3064</th>\n",
       "      <th>pixel_3065</th>\n",
       "      <th>pixel_3066</th>\n",
       "      <th>pixel_3067</th>\n",
       "      <th>pixel_3068</th>\n",
       "      <th>pixel_3069</th>\n",
       "      <th>pixel_3070</th>\n",
       "      <th>pixel_3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>162</td>\n",
       "      <td>159</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>123</td>\n",
       "      <td>145</td>\n",
       "      <td>167</td>\n",
       "      <td>182</td>\n",
       "      <td>175</td>\n",
       "      <td>145</td>\n",
       "      <td>124</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>133</td>\n",
       "      <td>141</td>\n",
       "      <td>153</td>\n",
       "      <td>163</td>\n",
       "      <td>178</td>\n",
       "      <td>191</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>139</td>\n",
       "      <td>132</td>\n",
       "      <td>166</td>\n",
       "      <td>182</td>\n",
       "      <td>187</td>\n",
       "      <td>193</td>\n",
       "      <td>199</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>155</td>\n",
       "      <td>167</td>\n",
       "      <td>176</td>\n",
       "      <td>190</td>\n",
       "      <td>177</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>166</td>\n",
       "      <td>170</td>\n",
       "      <td>179</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>55</td>\n",
       "      <td>70</td>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "      <td>72</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>127</td>\n",
       "      <td>156</td>\n",
       "      <td>139</td>\n",
       "      <td>131</td>\n",
       "      <td>130</td>\n",
       "      <td>147</td>\n",
       "      <td>136</td>\n",
       "      <td>146</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0      158      159      165      166      160      156      162      159   \n",
       "1      235      231      232      232      232      232      232      232   \n",
       "2      158      158      139      132      166      182      187      193   \n",
       "3      155      167      176      190      177      166      168      166   \n",
       "4       65       70       48       30       23       40       44       45   \n",
       "\n",
       "   pixel_8  pixel_9  ...  pixel_3062  pixel_3063  pixel_3064  pixel_3065  \\\n",
       "0      158      159  ...         130         123         145         167   \n",
       "1      232      232  ...         108         117         123         133   \n",
       "2      199      205  ...          45          46          44          44   \n",
       "3      170      179  ...          52          55          70         103   \n",
       "4       45       40  ...         102         127         156         139   \n",
       "\n",
       "   pixel_3066  pixel_3067  pixel_3068  pixel_3069  pixel_3070  pixel_3071  \n",
       "0         182         175         145         124         129         110  \n",
       "1         141         153         163         178         191         199  \n",
       "2          43          52          37           8           3           7  \n",
       "3         105          72          53          50          52          50  \n",
       "4         131         130         147         136         146         117  \n",
       "\n",
       "[5 rows x 3072 columns]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2553379e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "a59b0cc0-6b12-4578-bcb2-af92d09b12e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3073), (10000, 3072))"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train) , np.shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459257cd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e207097b-a356-4d88-8096-4a33ea499fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "41772bfd-34f5-4871-a840-4c0df59c2dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 4, 1, 2, 7, 8, 3, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "ec9ce2d4-8c02-4974-af2c-ff03fac9eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e61a8229-251d-450a-ba0f-f0e1b025fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size = 0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size = 0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "0afb9963-bf1a-4502-a419-591c68f2b0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 3072), (7500, 3072), (7500, 3072), (35000,))"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train), np.shape(x_test), np.shape(x_val) , np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a3fecc10-9477-4d22-b871-9b72dbe6a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_classes(target):\n",
    "    for i in range(0, 10) :\n",
    "        print(f\"le nombre d'éléments dans la classe {i} est : {(target == i).sum()*100/len(target) : .2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9beedf03-a359-40fe-b8ba-ef4cff2341a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre d'éléments dans la classe 0 est :  10.10%\n",
      "le nombre d'éléments dans la classe 1 est :  9.92%\n",
      "le nombre d'éléments dans la classe 2 est :  9.98%\n",
      "le nombre d'éléments dans la classe 3 est :  9.98%\n",
      "le nombre d'éléments dans la classe 4 est :  9.90%\n",
      "le nombre d'éléments dans la classe 5 est :  10.08%\n",
      "le nombre d'éléments dans la classe 6 est :  10.06%\n",
      "le nombre d'éléments dans la classe 7 est :  9.88%\n",
      "le nombre d'éléments dans la classe 8 est :  9.92%\n",
      "le nombre d'éléments dans la classe 9 est :  10.18%\n"
     ]
    }
   ],
   "source": [
    "counter_classes(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f8f28e0b-9e41-437d-b902-7223ac4d58b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le nombre d'éléments dans la classe 0 est :  9.56%\n",
      "le nombre d'éléments dans la classe 1 est :  10.29%\n",
      "le nombre d'éléments dans la classe 2 est :  9.96%\n",
      "le nombre d'éléments dans la classe 3 est :  9.79%\n",
      "le nombre d'éléments dans la classe 4 est :  10.52%\n",
      "le nombre d'éléments dans la classe 5 est :  9.97%\n",
      "le nombre d'éléments dans la classe 6 est :  10.13%\n",
      "le nombre d'éléments dans la classe 7 est :  10.13%\n",
      "le nombre d'éléments dans la classe 8 est :  10.25%\n",
      "le nombre d'éléments dans la classe 9 est :  9.39%\n"
     ]
    }
   ],
   "source": [
    "counter_classes(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "deb77504-b20d-4476-af75-5a2cc4c5216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization(mix max scaler :  max = 255 and min = 0)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82974d2e-f5f7-4516-b602-690f25dfaefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test = to_categorical(y_test, 10)\n",
    "Y_val = to_categorical(y_val, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "69815300-5f05-42b3-b269-3fd8021d482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 10)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c7dc5-0ad9-42af-af3e-d54cd4a562e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6931b524-ca97-4227-91c2-e81ac046fdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 3072)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "95796578-1f52-4d28-a907-1ba531e8fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train.reshape(x_train.shape[0], 32, 32, 3) #  1 2 0\n",
    "X_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
    "X_val = x_val.reshape(x_val.shape[0], 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5c78d385-8e7d-4f91-aa92-d898f02f7745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.21176471, 0.22745098, 0.50588235],\n",
       "        [0.64313725, 0.68235294, 0.77254902],\n",
       "        [0.58039216, 0.18823529, 0.27058824],\n",
       "        ...,\n",
       "        [0.45490196, 0.54901961, 0.45098039],\n",
       "        [0.74901961, 0.87058824, 0.82745098],\n",
       "        [0.79607843, 0.67843137, 0.6       ]],\n",
       "\n",
       "       [[0.24313725, 0.31764706, 0.55686275],\n",
       "        [0.67843137, 0.71764706, 0.78823529],\n",
       "        [0.58039216, 0.16078431, 0.21176471],\n",
       "        ...,\n",
       "        [0.46666667, 0.47843137, 0.63529412],\n",
       "        [0.85882353, 0.82352941, 0.82352941],\n",
       "        [0.79607843, 0.72156863, 0.58039216]],\n",
       "\n",
       "       [[0.27843137, 0.35294118, 0.58039216],\n",
       "        [0.69803922, 0.73333333, 0.78823529],\n",
       "        [0.56470588, 0.18431373, 0.24313725],\n",
       "        ...,\n",
       "        [0.4       , 0.40784314, 0.43529412],\n",
       "        [0.55294118, 0.78039216, 0.82352941],\n",
       "        [0.82352941, 0.78039216, 0.65098039]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.39215686, 0.39607843, 0.40784314],\n",
       "        [0.41568627, 0.41960784, 0.41568627],\n",
       "        [0.40392157, 0.41568627, 0.40784314],\n",
       "        ...,\n",
       "        [0.33333333, 0.38431373, 0.37647059],\n",
       "        [0.37254902, 0.34901961, 0.41568627],\n",
       "        [0.58431373, 0.63137255, 0.54509804]],\n",
       "\n",
       "       [[0.37254902, 0.37254902, 0.39215686],\n",
       "        [0.40784314, 0.41568627, 0.43137255],\n",
       "        [0.43921569, 0.42352941, 0.42745098],\n",
       "        ...,\n",
       "        [0.36078431, 0.36862745, 0.38039216],\n",
       "        [0.36862745, 0.36078431, 0.38823529],\n",
       "        [0.38431373, 0.38823529, 0.35686275]],\n",
       "\n",
       "       [[0.38823529, 0.40392157, 0.40784314],\n",
       "        [0.41568627, 0.42745098, 0.42745098],\n",
       "        [0.43137255, 0.44313725, 0.45490196],\n",
       "        ...,\n",
       "        [0.41176471, 0.43921569, 0.43921569],\n",
       "        [0.41960784, 0.42745098, 0.39607843],\n",
       "        [0.38823529, 0.38431373, 0.37647059]]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9dd9137a-7bcf-46a5-9a1c-409a8e56c20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 32, 32, 3)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5a0b61ad-8aae-48e4-a1c8-f97d9d3e2c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m  19/8750\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:24\u001b[0m 10ms/step - accuracy: 0.0738 - loss: 2.4390 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:199: UserWarning: Can save best model only with val_loss available, skipping.\n",
      "  self._save_model(epoch=self._current_epoch, batch=batch, logs=logs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 10ms/step - accuracy: 0.3366 - loss: 1.8060 - val_accuracy: 0.4860 - val_loss: 1.4390\n",
      "Epoch 2/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - accuracy: 0.5064 - loss: 1.3915 - val_accuracy: 0.5395 - val_loss: 1.3156\n",
      "Epoch 3/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 10ms/step - accuracy: 0.5487 - loss: 1.2641 - val_accuracy: 0.5453 - val_loss: 1.2752\n",
      "Epoch 4/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10ms/step - accuracy: 0.5757 - loss: 1.2001 - val_accuracy: 0.5756 - val_loss: 1.2163\n",
      "Epoch 5/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 10ms/step - accuracy: 0.5930 - loss: 1.1506 - val_accuracy: 0.5721 - val_loss: 1.2239\n",
      "Epoch 6/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 10ms/step - accuracy: 0.6151 - loss: 1.0925 - val_accuracy: 0.5864 - val_loss: 1.1880\n",
      "Epoch 7/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 10ms/step - accuracy: 0.6223 - loss: 1.0684 - val_accuracy: 0.5871 - val_loss: 1.1770\n",
      "Epoch 8/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 11ms/step - accuracy: 0.6410 - loss: 1.0195 - val_accuracy: 0.5916 - val_loss: 1.1834\n",
      "Epoch 9/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 11ms/step - accuracy: 0.6469 - loss: 1.0067 - val_accuracy: 0.5800 - val_loss: 1.1866\n",
      "Epoch 10/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 11ms/step - accuracy: 0.6595 - loss: 0.9675 - val_accuracy: 0.5996 - val_loss: 1.1693\n",
      "Epoch 11/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 11ms/step - accuracy: 0.6680 - loss: 0.9544 - val_accuracy: 0.5969 - val_loss: 1.1658\n",
      "Epoch 12/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 11ms/step - accuracy: 0.6730 - loss: 0.9254 - val_accuracy: 0.5811 - val_loss: 1.1983\n",
      "Epoch 13/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 11ms/step - accuracy: 0.6779 - loss: 0.9180 - val_accuracy: 0.6041 - val_loss: 1.1955\n",
      "Epoch 14/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 11ms/step - accuracy: 0.6928 - loss: 0.8744 - val_accuracy: 0.6041 - val_loss: 1.1776\n",
      "Epoch 15/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 11ms/step - accuracy: 0.6896 - loss: 0.8896 - val_accuracy: 0.5912 - val_loss: 1.2158\n",
      "Epoch 16/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 11ms/step - accuracy: 0.6975 - loss: 0.8631 - val_accuracy: 0.5984 - val_loss: 1.1838\n",
      "Epoch 17/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 12ms/step - accuracy: 0.7026 - loss: 0.8518 - val_accuracy: 0.6028 - val_loss: 1.1834\n",
      "Epoch 18/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 12ms/step - accuracy: 0.7074 - loss: 0.8337 - val_accuracy: 0.6147 - val_loss: 1.1805\n",
      "Epoch 19/400\n",
      "\u001b[1m8750/8750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 11ms/step - accuracy: 0.7082 - loss: 0.8327 - val_accuracy: 0.6047 - val_loss: 1.2036\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "batch_size = 4\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu', input_shape = (32, 32, 3), padding = 'same', strides = 1))\n",
    "model.add(MaxPooling2D((2,2), padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2,2), padding = 'same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath = 'CNN_model_cifar.keras', monitor = 'val_loss', verbose = 0, save_best_only = True, save_weights_only = False,\n",
    "                               mode = 'min', save_freq=1)\n",
    "early = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 8, verbose = 0, mode = 'auto') # min_delta = 0, ce qui signifie que toute amélioration, même minime, est suffisante pour continuer.\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy']) \n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs = num_epochs, batch_size = batch_size, validation_data = (X_val, Y_val), callbacks = [checkpointer, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "adf59d65-644e-40b9-8cee-d6ef431eac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "646aa859-3506-4ac5-93d8-673e905fa865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6142 - loss: 1.1790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1965242624282837, 0.6050666570663452]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "affa81d0-c8d4-4d37-b004-d4bcaffc6d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score , precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5bb50c4b-63ff-432c-95d0-27aa73521ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_classes = np.argmax(Y_test, axis=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "64a0a698-86f0-4e91-b034-e39fa89f3739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1321116047534563"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = log_loss(Y_test, y_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5dede289-0c03-4aef-a89e-8a523d468c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "009453fb-0508-4d54-8874-83e96bcb521d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[390,  19,  72,  20,  24,  13,  20,  39,  64,  56],\n",
       "       [ 11, 550,   8,  11,  13,   9,  41,  10,  23,  96],\n",
       "       [ 18,   1, 386,  43,  60,  75, 101,  44,   7,  12],\n",
       "       [ 10,   8,  56, 236,  46, 172, 123,  52,   6,  25],\n",
       "       [  8,   4,  94,  37, 390,  48, 104,  92,   7,   5],\n",
       "       [  5,   6,  38, 108,  31, 427,  52,  62,   7,  12],\n",
       "       [  6,   6,  38,  45,  41,  27, 577,   9,   1,  10],\n",
       "       [  8,   5,  18,  30,  44,  52,  26, 557,   3,  17],\n",
       "       [ 48,  43,  31,  16,  13,  12,  19,  12, 547,  28],\n",
       "       [ 12,  96,   6,  17,   8,  17,  25,  17,  24, 482]], dtype=int64)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e4d5ea27-6f77-4d46-8d7d-08bd2f1be9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6116250213458225"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test_classes, y_pred_classes, average = 'macro')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "309a7771-0420-4d66-8c32-3befc22c21f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6047857715188681"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test_classes, y_pred_classes, average = 'macro')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c33a0416-5754-45f2-8d95-e74e4af10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = f1_score(y_test_classes, y_pred_classes, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "0371db22-bdc7-4fe8-a905-2fce79d1d0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6024619803724975"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0242e5e6-453e-411c-ab4c-58a937e51a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756e011-0880-48f4-ab4b-b9129cc85f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
